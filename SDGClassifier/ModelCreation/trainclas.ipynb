{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952234f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_classical.py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import joblib\n",
    "import re\n",
    "from tqdm import tqdm  # Add this import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eee0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load your dataset\n",
    "df = pd.read_csv(\"youtube-comments-sentiment.csv\")\n",
    "df = df.sample(frac=0.3, random_state=42).reset_index(drop=True)\n",
    "comments = df[\"CommentText\"].tolist()\n",
    "labels = df[\"Sentiment\"].map({\"Negative\":0, \"Neutral\":1, \"Positive\":2}).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13c552f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\natur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\natur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Cleaning comments: 100%|██████████| 309668/309668 [01:30<00:00, 3432.65it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = text.split()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    stops.remove('not')  # keep 'not' for sentiment\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stops]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "clean_comments = [preprocess(comment) for comment in tqdm(comments, desc=\"Cleaning comments\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09cafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Preprocess (same as your BERT preprocessing)\n",
    "# def preprocess(text):\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "#     return text\n",
    "\n",
    "# comments_clean = [preprocess(c) for c in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d6ebea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Vectorize with TF-IDF (better than CountVectorizer)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=1000)\n",
    "X = vectorizer.fit_transform(clean_comments)\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4afd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "# from scipy.sparse import hstack, csr_matrix\n",
    "# nltk.download('vader_lexicon')\n",
    "\n",
    "# sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# def add_sentiment_features(text):\n",
    "#     scores = sia.polarity_scores(text)\n",
    "#     return [scores['pos'], scores['neg'], scores['neu']]\n",
    "\n",
    "# # Sentiment features (on original text)\n",
    "# X_extra = [add_sentiment_features(t) for t in tqdm(comments, desc=\"Adding sentiment scores\")]\n",
    "\n",
    "# # Combine features\n",
    "# X_combined = hstack([X, csr_matrix(X_extra)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb04d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load the vectorizer\n",
    "# vectorizer = joblib.load(\"classical_models/tfidf_vectorizer.pkl\")\n",
    "\n",
    "# X = vectorizer.transform(comments_clean)\n",
    "# y = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cd0a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "847cfa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. Train/Test Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5beefad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classical_models/y_test.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the vectorizer\n",
    "joblib.dump(vectorizer, \"classical_models/tfidf_vectorizer.pkl\")\n",
    "\n",
    "joblib.dump(X_train, \"classical_models/X_train.pkl\")\n",
    "joblib.dump(X_test, \"classical_models/X_test.pkl\")\n",
    "joblib.dump(y_train, \"classical_models/y_train.pkl\")\n",
    "joblib.dump(y_test, \"classical_models/y_test.pkl\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25fda44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the splitted data\n",
    "X_train = joblib.load(\"classical_models/X_train.pkl\")\n",
    "X_test = joblib.load(\"classical_models/X_test.pkl\") \n",
    "y_train = joblib.load(\"classical_models/y_train.pkl\")\n",
    "y_test = joblib.load(\"classical_models/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5b084",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8522881f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Naive Bayes...\n",
      "  Accuracy: 0.5282720315174217\n",
      "  Macro-F1: 0.5207781338847075\n",
      "  Confusion Matrix:\n",
      "[[10946  4396  5440]\n",
      " [ 5091  7685  7792]\n",
      " [ 3476  3021 14087]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['classical_models/NaiveBayes_model.pkl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=GaussianNB()\n",
    "# model = joblib.load(\"classical_models/NaiveBayes_model.pkl\")\n",
    "\n",
    "print(f\"\\nTraining Naive Bayes...\")\n",
    "model.fit(X_train.toarray(), y_train)\n",
    "y_pred = model.predict(X_test.toarray())\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"  Accuracy: {acc}\")\n",
    "print(f\"  Macro-F1: {f1}\")\n",
    "print(f\"  Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "joblib.dump(model, f\"classical_models/NaiveBayes_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a544d1d",
   "metadata": {},
   "source": [
    "SDGclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07d18e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SDGclassifier...\n",
      "  Accuracy: 0.5955210385248814\n",
      "  Macro-F1: 0.5976096475214091\n",
      "  Confusion Matrix:\n",
      "[[12258  6326  2198]\n",
      " [ 5212 12357  2999]\n",
      " [ 3525  4791 12268]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['classical_models/SGDClassifier_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=SGDClassifier(loss='log_loss', max_iter=1000)\n",
    "# model = joblib.load(\"classical_models/SGDClassifier_model.pkl\")\n",
    "\n",
    "\n",
    "print(f\"\\nTraining SDGclassifier...\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"  Accuracy: {acc}\")\n",
    "print(f\"  Macro-F1: {f1}\")\n",
    "print(f\"  Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "joblib.dump(model, f\"classical_models/SGDClassifier_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b72ef",
   "metadata": {},
   "source": [
    "Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97bdb528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "  Accuracy: 0.6173022895340201\n",
      "  Macro-F1: 0.6189651441072018\n",
      "  Confusion Matrix:\n",
      "[[12862  5715  2205]\n",
      " [ 4917 12598  3053]\n",
      " [ 3145  4667 12772]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['classical_models/LogRegress_model.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(max_iter=1000)\n",
    "# model = joblib.load(\"classical_models/LogRegress_model.pkl\")\n",
    "\n",
    "\n",
    "print(f\"\\nTraining Logistic Regression...\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"  Accuracy: {acc}\")\n",
    "print(f\"  Macro-F1: {f1}\")\n",
    "print(f\"  Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "joblib.dump(model, f\"classical_models/LogRegress_model.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b088d7",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e11af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Decision Trees...\n",
      "  Accuracy: 0.5788904317499274\n",
      "  Macro-F1: 0.5808441541711924\n",
      "  Confusion Matrix:\n",
      "[[11810  7105  1867]\n",
      " [ 4707 13214  2647]\n",
      " [ 3432  6323 10829]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['classical_models/DecisionTrees_model.pkl']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=DecisionTreeClassifier( max_depth=15, min_samples_leaf=10)\n",
    "# model = joblib.load(\"classical_models/DecisionTrees_model.pkl\")\n",
    "\n",
    "\n",
    "print(f\"\\nTraining Decision Trees...\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"  Accuracy: {acc}\")\n",
    "print(f\"  Macro-F1: {f1}\")\n",
    "print(f\"  Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "joblib.dump(model, f\"classical_models/DecisionTrees_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e4b492",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1861268f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest...\n",
      "  Accuracy: 0.5796331578777408\n",
      "  Macro-F1: 0.5816186013185404\n",
      "  Confusion Matrix:\n",
      "[[11656  7015  2111]\n",
      " [ 4447 12587  3534]\n",
      " [ 3415  5513 11656]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['classical_models/Randomforest_model.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier(n_estimators=50,  # Reduce from 100\n",
    "    max_depth=15,     # Limit tree depth\n",
    "    min_samples_leaf=10,\n",
    "    n_jobs=-1         # Parallelize)\n",
    ")\n",
    "# model = joblib.load(\"classical_models/Randomforest_model.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nTraining Random Forest...\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"  Accuracy: {acc}\")\n",
    "print(f\"  Macro-F1: {f1}\")\n",
    "print(f\"  Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "joblib.dump(model, f\"classical_models/Randomforest_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc664d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RankYT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
